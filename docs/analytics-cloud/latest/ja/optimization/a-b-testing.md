# A/Bテスト

A/Bテストは、複数のバージョンのページを一度にテストすることで、コンテンツページの効果を評価するものです。 このプロセスでは、ページバリアントを作成し、メトリクス（クリック数など）でテストして、最も効果的なバリアントを公開します。 これらのテストは、あなたのサイトのユーザーにとって最適なエクスペリエンスを選択するのに役立ちます。

A/B テストの作成とコンテンツページへの設定については、Liferay DXP の [A/Bテスト](https://learn.liferay.com/dxp/latest/ja/site-building/optimizing-sites/ab-testing/ab-testing.html) で詳しく説明されています。

Analytics Cloudは、Liferay DXPで実行されたA/Bテストのすべての結果を追跡します。 作成されたテストは、Analytics Cloudと自動的に同期され、そこで管理することができます。 ドラフト、実行中、終了、完了した A/B テストを表示するには、左カラムの **Tests** メニューにアクセスします。

![テスト」メニューには、サイトに対して作成・定義されたすべてのA/Bテストが表示されます。](a-b-testing/images/01.png)

ドラフト式A/Bテストでは、これらの詳細を設定することができます。

* ターゲット：体験者層、ユーザー層。
* メトリック：追跡する目標（例：直帰率やクリック）。
* バリアント：ユーザーが対話するためのページバリアントです。
* トラフィック・スプリット：バリアント間でランダムに分割される訪問者の割合です。
* 信頼度：テスト結果の正確さ。

![このA/Bテストは設定され、実行できる状態になっています。](a-b-testing/images/02.png)

A/Bテストが実行されると、Analytics Cloudはこれらのレポートを提供し、その進捗を常に把握することができます。

* [概要](#summary)
* [バリエーション レポート](#variant-report)
* [テストセッション](#test-sessions)

## 概要

サマリーパネルでは、完了率、実行時間（日数）、訪問者の総セッション数など、テストの詳細の概要を確認することができます。

また、メトリクスの詳細や現在最もパフォーマンスの高いバリアントを簡単に要約することができます。

![Summary」パネルでは、テストの概要が表示されます。](a-b-testing/images/03.png)

## バリアントレポート

バリアントレポートパネルでは、バリアントの詳細な内訳とそのパフォーマンスについて確認できます。

![バリアントレポートパネルでは、バリアントの詳細な内訳と、そのパフォーマンスの高さを確認できます。](a-b-testing/images/04.png)

以下は、各バリアントについて報告されたメトリクスです。

**中央値。** サンプル値の集合の中の真ん中の数字。 これは、典型的なユーザーの行動を推定します。

**Confidence Interval（信頼区間）。** 母集団の真の平均値を含むと予想される値の範囲。 例えば、95信頼区間とは、システムが真の平均値を含むことを95%確信している値の範囲のことです。 これは、測定された目標に対してもっともらしいと思われる値の範囲を与えます。

**改善されたこと。** 対照群からの相対的な改善度。 この指標は、リフトと呼ばれることもあります。 例えば、コントロールページの継続率が15％で、バリアントページの継続率が16％だったとします。 改善の計算は、 `((16 - 15) / 15) = ~6.67%` 改善となります。 これは、変化の影響を示しています。 わずかな改善しかないのであれば、その変更を実施する価値はないかもしれません。

**勝つ確率。** あるバリアントが他の参加バリアントに勝つ可能性を予測します。 複数の指標を比較して表示します。 例えば、競馬を考えてみましょう。各馬には、何千回もレースをシミュレーションして算出された勝率（＝オッズ）がレース前に掲示されています。 これと同じ方法で、バリアントもA/Bテストに勝つ確率を計算します。

**ユニークビジター。** バリアントに貢献した訪問者の数。 ランダムにバリアントが割り当てられた訪問者は、テスト終了まで常に同じバリアントを見ることになります。 この指標は、ページにアクセスするトラフィックの量を知る以外にも、A/Bテストの設定上の問題点を判断するのに役立ちます。 例えば、あるバリアントへのトラフィックが多すぎる可能性があります（一般的にセグメントの設定ミスが原因）。

## テストセッション

テストセッション」パネルには、1日あたりのテストインプレッションを閲覧したセッション数が時系列で表示されます。 これにより、オーディエンスがA/Bテストのインプレッションに誘導されていることを確認することができます。 また、テスト開始前と比較して、テストがページへのトラフィックにどのような影響を与えるかも描かれます。

![テストセッション」パネルでは、1日あたりのテストインプレッションを閲覧するセッションを時系列で表示します。](a-b-testing/images/05.png)

次に、A/Bテストのステータスについてです。

## テストステータス

A/Bテストは、開始後に必ずステータスが付いているのが特徴です。 これらには以下のものが含まれます。

* [テストが実行されている](#test-is-running)
* [勝者が宣言されました](#winner-declared)
* [明確な勝者がいません](#no-clear-winner)

### テストが実行されている

これは、テストが実行されていることを意味し、望ましい信頼レベルに到達して勝者を宣言する前に、より大きなサンプルサイズが必要であることを意味します。 現在のベストバリエーションを表示することができます。

![現在のベストバリアントを表示することができますが、テストは実行中です。](a-b-testing/images/06.png)

テストの実行中に、サマリーバーから **Terminate Test** を選択すると、テストを終了させることができます。

![実行中のテストを終了する場合は、「Terminate Test」をクリックします。](a-b-testing/images/07.png)

```{important}
A/Bテストを成功させるためには、大量のトラフィック（1日数千アクセスなど）が必要です。 そのため、一般公開されているサイトはテストに適しています。 社内サイトやポータルの場合、テスト終了までにかなり時間がかかる場合があります。
```

### 勝者が宣言されました

A/Bテストが正常に終了すると、バリアントが勝者として宣言されます。 この状態に対して、以下のアクションを実行することができます。

* 勝利したバリアントをデフォルトのエクスペリエンスとして公開する。
* バリアントを公開せずにテストを完了する。

![A/Bテスト終了後に勝者を公開することができます。](a-b-testing/images/08.png)

### クリア勝者なし

どのバリアントもコントロールページを大きく上回っていないため、Analytics Cloudが勝者を決定できないこともあります。 この場合、パブリッシュせずにテストを完了させ、コントロールはデフォルトのエクスペリエンスのままとなります。

![バリアントによるパフォーマンスの不足は、明確な勝者がいないA/Bテストにつながる可能性があります。 ](a-b-testing/images/09.png)
