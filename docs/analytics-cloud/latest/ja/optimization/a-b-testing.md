# A/Bテスト

A/Bテストは、コントロールデザイン（つまりオリジナル）に対してバリアントデザインをテストすることで、コンテンツページの効果を評価します。 このプロセスでは、ページのバリアントを作成し、指標（クリック数など）でテストし、最も効果的なバリアントを公開します。 これらのテストは、サイトのユーザーにとって最適なエクスペリエンスを選択するのに役立ちます。

Liferay DXP の [A/Bテスト](https://learn.liferay.com/dxp/latest/ja/site-building/optimizing-sites/ab-testing/ab-testing.html) で、A/B テストの作成とコンテンツページへの設定について詳しく知ることができます。

Analytics Cloudは、Liferay DXPで実行されたA/Bテストのすべての結果を追跡します。 テストが作成されると、Analytics Cloudと自動的に同期されます。 A/Bテストを表示するには、左側のメニューから **Test** 。

![［テスト］メニューには、サイトのために作成・定義されたすべてのA/Bテストが表示されます。](a-b-testing/images/01.png)

下書きのA/Bテストでは、これらの詳細を見ることができます：

* ターゲット： エクスペリエンスとユーザーセグメント
* メトリクス： 追跡する目標（バウンス率やクリック率など）。
* Variant: ユーザーがインタラクトするページバリアント。

![A/Bテストは設定され、実行する準備ができている。](a-b-testing/images/02.png)

DXP で A/B テストページを表示するには、 **Review** をクリックします。 A/Bテストを削除するには、 **Delete** をクリックします。

A/Bテストが実行されると、Analytics Cloudはこれらのレポートを提供し、その進捗を常に把握することができます。

* [概要](#summary)
* [バリエーション レポート](#variant-report)
* [テストセッション](#test-sessions)

## 概要

［Summary］パネルでは、完了率、実行時間（日数）、訪問者の総セッション数など、テストの詳細の概要を確認することができます。

また、メトリクスの詳細と、バリアントがコントロールに対してどのようなパフォーマンスをしているかを簡単に要約します。

![サマリーパネルには、テストの概要が表示されます。](a-b-testing/images/03.png)

## バリアントレポート

バリアントレポートパネルは、バリアントがコントロールに対してどのように動作しているかの詳細な内訳を提供します。

![バリアントレポートパネルは、バリアントの詳細な内訳と、そのバリアントがどの程度のパフォーマンスをしているかを提供します。](a-b-testing/images/04.png)

以下は報告された指標である：

**中央値：** サンプル値の集合内の中間値。 これは、典型的なユーザーの行動を推定します。

**直帰率またはクリック率：** コントロールとバリアントの直帰率またはクリック率のパーセンテージ。 表示される指標は、選択されたA/Bテストのタイプに基づいています。

**信頼区間：** 母集団の真の平均を含むと期待される値の範囲。 例えば、95信頼区間とは、システムが真の平均値を含むことを95%確信している値の範囲のことです。 これは、測定された目標に対してもっともらしいと思われる値の範囲を与えます。

**改善：** 対照群からの相対的な改善。 このメトリックは、リフトとしても知られています。 例えば、コントロールページの保持率が15％で、バリアントページの保持率が16％だったとします。 改善の計算は、 `((16 - 15) / 15) = ~6.67%` 改善となります。 これは、変化の影響を示しています。 わずかな改善しかないのであれば、その変更を実施する価値はないかもしれません。

**勝つ確率：** 変種がコントロールに勝つ可能性を予測する。 複数のメトリクスを比較して表示します。 例えば、競馬を考えてみましょう。各馬には、何千回もレースをシミュレーションして算出された勝率（＝オッズ）がレース前に掲示されています。 これと同じ方法で、バリアントもA/Bテストに勝つ確率を計算します。

**ユニークビジター：** バリアントに貢献している訪問者の数。 ランダムにバリアントを割り当てられた訪問者は、テストが終了するまで常に同じバリアントを見ています。 このメトリクスは、ページにアクセスするトラフィックの量を知る以外にも、A/Bテストの設定上の問題点を判断するのに役立ちます。 例えば、ある Variant に行くトラフィックが多すぎる可能性があります (通常、Segment の設定ミスが原因です)。

## テストセッション

［Test Sessions］パネルには、1日あたりのテストインプレッションの閲覧セッション数が時系列で表示されます。 これにより、オーディエンスがA/Bテストのインプレッションに誘導されていることを確認することができます。 また、テスト開始前と比較して、テストがページへのトラフィックにどのような影響を与えるかも示しています。

![［Test Sessions］パネルには、1日あたりのテストインプレッションの閲覧セッションが時系列で表示されます。](a-b-testing/images/05.png)

次に、A/Bテストのステータスについてです。

## テストステータス

A/Bテストが開始されると、以下のステータスのいずれかになります：

* [テストを実行中](#test-is-running)
* [勝者が宣言されました](#winner-declared)
* [明確な勝者がいません](#no-clear-winner)
* [テスト終了](#test-terminated)

### テストを実行中

あなたのテストは実行中であり、望ましい信頼レベルに達して勝者を宣言する前に、より大きなサンプルサイズが必要である。 現在の結果を見ることができる。

![現在の結果を見ることができますが、テストは実行中です。](a-b-testing/images/06.png)

テストの実行中に、サマリーバーから **Terminate Test** を選択すると、テストを終了できます。

![［Terminate Test］をクリックして、実行中のテストを終了します。](a-b-testing/images/07.png)

```{important}
A/Bテストを成功させるには、多くのトラフィック（つまり1日数千ヒット）が必要である。 このため、一般向けのサイトはテストに適している。 社内サイトやポータルの場合、テスト終了までにかなり時間がかかる場合があります。
```

### 勝者が宣言されました

A/Bテストが成功すると、勝者が宣言されます（つまり、バリアントまたはコントロールが勝ったということです）。 ここから、以下のアクションを実行できる：

* 勝者をデフォルトのエクスペリエンスとして公開する。
* 変更を公開せずにテストを削除する。

![A/Bテスト終了後に勝者を公開することができます。](a-b-testing/images/08.png)

### 明確な勝者がいません

バリアントがコントロールページを大きく上回っていないため、Analytics Cloud が勝者を決定できないことがあります。 この場合でも、 **Publish** をクリックして、バリアントをパブリッシュすることができます。 または、 **Delete** をクリックして、A/Bテストを削除します。

![バリアントによるパフォーマンスの不足は、明確な勝者がいないA/Bテストにつながる可能性があります。 ](a-b-testing/images/09.png)

### テスト終了

勝者が決定する前にA/Bテストが終了した場合、テストステータスは終了と表示されます。

![早期に終了したテストは、終了したテストとして表示される。](./a-b-testing/images/10.png)

```{note}
終了したA/Bテストは、指定された信頼水準に達しておらず、本質的に信頼性の低い結果となる。
```

**Publish** ボタンをクリックして、バリアントを発行することもできます。 または、 **Delete** をクリックして、A/Bテストを削除します。
